"""
ES Review Router

AI-powered ES (Entry Sheet) review and feedback using LLM.

Scoring axes (SPEC Section 16.2):
- è«–ç† (logic): è«–ç†ã®ä¸€è²«æ€§
- å…·ä½“æ€§ (specificity): å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰
- ç†±æ„ (passion): ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦
- ä¼æ¥­æ¥ç¶š (company_connection): ä¼æ¥­ã¨ã®æ¥ç¶šåº¦ï¼ˆRAGå–å¾—æ™‚ã®ã¿è©•ä¾¡ï¼‰
- èª­ã¿ã‚„ã™ã• (readability): æ–‡ç« ã®èª­ã¿ã‚„ã™ã•

Style options (SPEC Section 16.3):
- Free: ãƒãƒ©ãƒ³ã‚¹/å …ã‚/å€‹æ€§å¼·ã‚ (3 types)
- Paid: above + çŸ­ã/ç†±æ„å¼·ã‚/çµè«–å…ˆå‡ºã—/å…·ä½“ä¾‹å¼·ã‚/ç«¯çš„ (8 types)
"""

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, AsyncGenerator
import json
import asyncio
import math

from app.config import settings
from app.utils.llm import call_llm_with_error, call_llm_streaming
from app.utils.vector_store import (
    get_company_context_for_review,
    get_enhanced_context_for_review,
    get_enhanced_context_for_review_with_sources,
    has_company_rag,
    get_company_rag_status,
    get_dynamic_context_length,
)
from app.utils.cache import get_es_review_cache, build_cache_key
from app.utils.telemetry import (
    record_es_scores,
    record_parse_failure,
    record_rag_context,
)
from app.prompts.es_templates import (
    TEMPLATE_DEFS,
    build_template_prompt,
    validate_template_output,
)

router = APIRouter(prefix="/api/es", tags=["es-review"])

# Style options per plan
FREE_STYLES = ["ãƒãƒ©ãƒ³ã‚¹", "å …ã‚", "å€‹æ€§å¼·ã‚"]
PAID_STYLES = FREE_STYLES + ["çŸ­ã", "ç†±æ„å¼·ã‚", "çµè«–å…ˆå‡ºã—", "å…·ä½“ä¾‹å¼·ã‚", "ç«¯çš„"]


class SectionDataInput(BaseModel):
    """Section data with character limit for review"""

    title: str
    content: str
    char_limit: Optional[int] = None


# Template-based review types (must be defined before ReviewRequest)
class TemplateRequest(BaseModel):
    """Request for template-based ES review."""

    template_type: str  # Template ID from TEMPLATE_DEFS
    company_name: Optional[str] = None
    industry: Optional[str] = None
    question: str  # ES question text
    answer: str  # User's answer
    char_min: Optional[int] = None
    char_max: Optional[int] = None
    intern_name: Optional[str] = None  # Intern program name (for intern templates)
    role_name: Optional[str] = (
        None  # Role/course name (for role_course_reason template)
    )


class TemplateVariant(BaseModel):
    """A single variant in template review."""

    text: str
    char_count: int
    pros: list[str]
    cons: list[str]
    keywords_used: list[str]
    keyword_sources: list[str]


class TemplateSource(BaseModel):
    """Source reference for template keywords."""

    source_id: str
    source_url: str
    content_type: str
    excerpt: Optional[str] = None


class TemplateReview(BaseModel):
    """Template-based review result."""

    template_type: str
    variants: list[TemplateVariant]
    keyword_sources: list[TemplateSource]
    strengthen_points: Optional[list[str]] = None


class ReviewRequest(BaseModel):
    content: str
    section_id: Optional[str] = None
    style: str = "ãƒãƒ©ãƒ³ã‚¹"  # Rewrite style
    is_paid: bool = False  # Whether user is on paid plan
    has_company_rag: bool = False  # Whether company RAG data is available
    company_id: Optional[str] = None  # Company ID for RAG context lookup
    rewrite_count: int = 1  # Number of rewrites (Free: 1, Paid: 3)
    # H2 sections for è¨­å•åˆ¥æŒ‡æ‘˜ (paid only)
    sections: Optional[list[str]] = None
    # Section data with character limits (paid only)
    section_data: Optional[list[SectionDataInput]] = None
    # Review mode: "full" for entire ES, "section" for single question
    review_mode: str = "full"  # "full" | "section"
    # Section-specific fields (used when review_mode="section")
    section_title: Optional[str] = None  # Question title for section review
    section_char_limit: Optional[int] = None  # Character limit for section
    # Template-based review (used when review_mode="section")
    template_request: Optional[TemplateRequest] = None
    # Gakuchika context
    gakuchika_context: Optional[str] = None  # Context from gakuchika deep-dive (key_points, strengths)


class Score(BaseModel):
    logic: int  # 1-5: è«–ç†ã®ä¸€è²«æ€§
    specificity: int  # 1-5: å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰
    passion: int  # 1-5: ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦
    company_connection: Optional[int] = None  # 1-5: ä¼æ¥­æ¥ç¶šï¼ˆRAGå–å¾—æ™‚ã®ã¿ï¼‰
    readability: int  # 1-5: èª­ã¿ã‚„ã™ã•


class Issue(BaseModel):
    category: str  # è©•ä¾¡ã‚«ãƒ†ã‚´ãƒª
    issue: str  # å•é¡Œç‚¹ã®èª¬æ˜
    suggestion: str  # æ”¹å–„ææ¡ˆ
    difficulty: Optional[str] = None  # easy | medium | hard


class SectionFeedback(BaseModel):
    section_title: str  # H2 section title
    feedback: str  # 100-150 chars feedback
    rewrite: Optional[str] = None  # Section-specific rewrite respecting char limit


class ReviewResponse(BaseModel):
    scores: Score
    top3: list[Issue]
    rewrites: list[str]  # Multiple rewrites based on plan
    section_feedbacks: Optional[list[SectionFeedback]] = None  # Paid only
    template_review: Optional[TemplateReview] = None  # Template-based review result


def parse_validation_errors(
    variants: list[dict],
    char_min: Optional[int],
    char_max: Optional[int],
) -> list[dict]:
    """
    Parse validation results to extract specific character deltas for each variant.

    Args:
        variants: List of variant dicts from LLM response
        char_min: Minimum character count (optional)
        char_max: Maximum character count (optional)

    Returns:
        List of error dicts with pattern, current, target, delta, direction
    """
    errors = []
    for i, variant in enumerate(variants, 1):
        text = variant.get("text", "")
        current = len(text)

        if char_max and current > char_max:
            errors.append(
                {
                    "pattern": i,
                    "current": current,
                    "target": char_max,
                    "delta": current - char_max,
                    "direction": "reduce",
                }
            )
        elif char_min and current < char_min:
            errors.append(
                {
                    "pattern": i,
                    "current": current,
                    "target": char_min,
                    "delta": char_min - current,
                    "direction": "expand",
                }
            )
    return errors


def build_char_adjustment_prompt(
    variant_errors: list[dict],
    char_min: Optional[int],
    char_max: Optional[int],
) -> str:
    """
    Build specific adjustment instructions for each failing variant.

    Enhanced with:
    - Structural compression strategies for Japanese text
    - Safety margin approach (aim for 5% below limit)
    - Detailed compression/expansion techniques

    Args:
        variant_errors: List of error dicts from parse_validation_errors
        char_min: Minimum character count (optional)
        char_max: Maximum character count (optional)

    Returns:
        Adjustment instructions string with specific deltas and guidance
    """
    if not variant_errors:
        return ""

    instructions = []
    for err in variant_errors:
        pattern_num = err["pattern"]
        current = err["current"]
        target = err["target"]
        delta = err["delta"]
        direction = err["direction"]

        # Calculate safety margin (aim for 10% below/above limit)
        if direction == "reduce":
            safety_target = int(target * 0.90)
            safety_delta = current - safety_target
            instructions.append(
                f"ãƒ‘ã‚¿ãƒ¼ãƒ³{pattern_num}: ç¾åœ¨{current}å­— â†’ ç›®æ¨™{safety_target}å­—ä»¥ä¸‹ï¼ˆä½™è£•ã‚’æŒã£ã¦{safety_delta}å­—å‰Šæ¸›ï¼‰\n"
                f"  ã€å‰Šæ¸›æ‰‹é †ã€‘\n"
                f"  1. å†—é•·ãªæ¥ç¶šè¡¨ç¾ã‚’å‰Šé™¤\n"
                f"     - ã€Œã€œã¨ã„ã†ã“ã¨ã€â†’ã€Œã€œã“ã¨ã€\n"
                f"     - ã€Œã€œã•ã›ã¦ã„ãŸã ãã€â†’ã€Œã€œã™ã‚‹ã€\n"
                f"     - ã€Œã€œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€â†’ã€Œã€œã§ãã‚‹ã€\n"
                f"  2. é‡è¤‡ã™ã‚‹ä¿®é£¾èªã‚’çµ±åˆ\n"
                f"     - ã€Œéå¸¸ã«å¤§ããªã€â†’ã€Œå¤§ããªã€\n"
                f"  3. æ•°å€¤ãƒ»å›ºæœ‰åè©ã¯æ®‹ã—ã€æŠ½è±¡çš„ãªå½¢å®¹è©ã‚’å‰Šæ¸›"
            )
        else:  # expand
            safety_target = int(target * 1.05)
            safety_delta = safety_target - current
            instructions.append(
                f"ãƒ‘ã‚¿ãƒ¼ãƒ³{pattern_num}: ç¾åœ¨{current}å­— â†’ ç›®æ¨™{safety_target}å­—ä»¥ä¸Šï¼ˆä½™è£•ã‚’æŒã£ã¦{safety_delta}å­—è¿½åŠ ï¼‰\n"
                f"  ã€è¿½åŠ æ‰‹é †ã€‘\n"
                f"  1. å…·ä½“çš„ãªæ•°å€¤ã‚’è¿½åŠ ï¼ˆæœŸé–“ã€äººæ•°ã€æˆæœã®æ•°å­—ï¼‰\n"
                f"  2. çŠ¶æ³èª¬æ˜ã‚’è¿½åŠ ï¼ˆã€Œã€œã®çŠ¶æ³ä¸‹ã§ã€ã€Œã€œã¨ã„ã†èª²é¡Œã«ç›´é¢ã—ã€ï¼‰\n"
                f"  3. å­¦ã³ã®è£œå¼·ï¼ˆã€Œã“ã®çµŒé¨“ã‹ã‚‰ã€œã‚’å­¦ã‚“ã ã€ï¼‰"
            )

    # Build constraint description
    if char_min and char_max:
        constraint = f"{char_min}ã€œ{char_max}å­—"
    elif char_max:
        constraint = f"{char_max}å­—ä»¥å†…"
    else:
        constraint = f"{char_min}å­—ä»¥ä¸Š"

    return f"""ã€æ–‡å­—æ•°èª¿æ•´ - ä»¥ä¸‹ã®æ‰‹é †ã§æ®µéšçš„ã«ä¿®æ­£ã€‘

{chr(10).join(instructions)}

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
1. ä¿®æ­£å¾Œã«å¿…ãš len(text) ã§æ–‡å­—æ•°ã‚’è¨ˆç®—
2. char_count ã«ã¯å®Ÿéš›ã®æ–‡å­—æ•°ã‚’æ­£ç¢ºã«è¨˜éŒ²
3. ç›®æ¨™: {constraint}
4. JSONæ§‹é€ ã¯å¤‰æ›´ã›ãšã€variants[*].text ã®ã¿ä¿®æ­£
5. æ„å‘³ã‚’å¤§ããå¤‰ãˆãšã«èª¿æ•´ï¼ˆå…·ä½“æ€§ã¯ç¶­æŒï¼‰"""


def validate_and_repair_section_rewrite(
    rewrite: Optional[str],
    char_limit: Optional[int],
) -> Optional[str]:
    """
    Validate section rewrite against character limit and repair if needed.

    This ensures that section rewrites respect the specified character limit,
    making them directly usable by the user without further editing.

    Args:
        rewrite: The rewrite text to validate
        char_limit: Maximum character count (optional)

    Returns:
        Validated rewrite, truncated at natural boundary if over limit
    """
    if rewrite is None or char_limit is None:
        return rewrite

    current_len = len(rewrite)
    if current_len <= char_limit:
        return rewrite

    # Over limit - attempt smart truncation at natural break points
    # Japanese sentence endings: ã€‚ã€ï¼‰ã€
    target_pos = char_limit - 5  # Leave margin for clean ending

    # Look for natural break point (sentence end) near target
    for i in range(target_pos, max(0, target_pos - 50), -1):
        if i < len(rewrite) and rewrite[i] in ("ã€‚", "ã€", "ï¼‰", "ã€"):
            return rewrite[: i + 1]

    # No natural break found - truncate with ellipsis indicator
    return rewrite[: char_limit - 3] + "..."


def should_attempt_conditional_retry(
    template_review_data: dict,
    char_min: Optional[int],
    char_max: Optional[int],
    rewrite_count: int = 3,
) -> tuple[bool, list[int]]:
    """
    Determine if a conditional retry is worthwhile based on partial success.

    For multiple variants: returns True if at least 2 pass character validation.
    For single variant: not applicable (main retry loop handles it).

    Args:
        template_review_data: The template_review dict from LLM response
        char_min: Minimum character count (optional)
        char_max: Maximum character count (optional)
        rewrite_count: Expected number of variants

    Returns:
        Tuple of (should_retry, failing_variant_indices)
    """
    variants = template_review_data.get("variants", [])
    if len(variants) != rewrite_count:
        return False, []

    # Single variant: conditional retry not applicable (main retry handles it)
    if rewrite_count == 1:
        return False, []

    failing_indices = []

    for i, variant in enumerate(variants):
        text = variant.get("text", "")
        char_count = len(text)

        # Check if this variant fails character limits
        if char_max and char_count > char_max:
            failing_indices.append(i)
        elif char_min and char_count < char_min:
            failing_indices.append(i)

    # Worth retrying if at least 2 variants pass (only minority fail)
    passing_count = len(variants) - len(failing_indices)
    should_retry = passing_count >= 2 and len(failing_indices) > 0

    return should_retry, failing_indices


def build_targeted_variant_repair_prompt(
    template_review_data: dict,
    failing_indices: list[int],
    char_min: Optional[int],
    char_max: Optional[int],
) -> str:
    """
    Build a repair prompt targeting only the failing variants.

    This allows more focused repair with lower token usage.

    Args:
        template_review_data: The template_review dict from LLM response
        failing_indices: List of variant indices that need repair
        char_min: Minimum character count (optional)
        char_max: Maximum character count (optional)

    Returns:
        Repair prompt string
    """
    variants = template_review_data.get("variants", [])
    repairs_needed = []

    for idx in failing_indices:
        if idx >= len(variants):
            continue
        variant = variants[idx]
        current_len = len(variant.get("text", ""))

        if char_max and current_len > char_max:
            excess = current_len - char_max
            repairs_needed.append(
                f"variants[{idx}]: {current_len}å­— â†’ {char_max}å­—ä»¥ä¸‹ã«{excess}å­—å‰Šæ¸›"
            )
        elif char_min and current_len < char_min:
            shortage = char_min - current_len
            repairs_needed.append(
                f"variants[{idx}]: {current_len}å­— â†’ {char_min}å­—ä»¥ä¸Šã«{shortage}å­—è¿½åŠ "
            )

    return f"""ä»¥ä¸‹ã®JSONã®ã†ã¡ã€æŒ‡å®šã•ã‚ŒãŸvariantsã®æ–‡å­—æ•°ã®ã¿ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ã€ä¿®æ­£å¯¾è±¡ã€‘
{chr(10).join(repairs_needed)}

ã€ä¿®æ­£ãƒ«ãƒ¼ãƒ«ã€‘
1. æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®textã®ã¿ä¿®æ­£
2. ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ä¸€åˆ‡å¤‰æ›´ã—ãªã„
3. char_countã«ã¯ä¿®æ­£å¾Œã®len(text)ã‚’è¨˜éŒ²
4. JSONä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„

ã€ä¿®æ­£ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã€‘
- å‰Šæ¸›: ã€Œã€œã¨ã„ã†ã“ã¨ã€â†’ã€Œã€œã“ã¨ã€ã€Œã€œã•ã›ã¦ã„ãŸã ãã€â†’ã€Œã€œã™ã‚‹ã€
- è¿½åŠ : å…·ä½“çš„ãªæ•°å€¤ã€çŠ¶æ³èª¬æ˜ã€å­¦ã³ã®è£œå¼·

å¯¾è±¡JSON:
{json.dumps(template_review_data, ensure_ascii=False)}"""


def build_es_review_schema(
    require_company_connection: bool,
    include_template_review: bool,
    include_section_feedbacks: bool,
    include_rewrites: bool = True,
    top3_max_items: int = 3,
    keyword_source_excerpt_required: bool = True,
    variant_count: int = 3,
) -> dict:
    """Build JSON schema for ES review output (OpenAI Structured Outputs)."""
    score_properties = {
        "logic": {"type": "integer", "minimum": 1, "maximum": 5},
        "specificity": {"type": "integer", "minimum": 1, "maximum": 5},
        "passion": {"type": "integer", "minimum": 1, "maximum": 5},
        "readability": {"type": "integer", "minimum": 1, "maximum": 5},
        "company_connection": {"type": "integer", "minimum": 1, "maximum": 5},
    }
    score_required = ["logic", "specificity", "passion", "readability"]
    if require_company_connection:
        score_required.append("company_connection")

    issue_schema = {
        "type": "object",
        "additionalProperties": False,
        "required": ["category", "issue", "suggestion", "difficulty"],
        "properties": {
            "category": {"type": "string"},
            "issue": {"type": "string"},
            "suggestion": {"type": "string"},
            "difficulty": {"type": "string", "enum": ["easy", "medium", "hard"]},
        },
    }

    section_feedback_schema = {
        "type": "object",
        "additionalProperties": False,
        "required": ["section_title", "feedback"],
        "properties": {
            "section_title": {"type": "string"},
            "feedback": {"type": "string"},
            "rewrite": {"type": "string"},
        },
    }

    variant_schema = {
        "type": "object",
        "additionalProperties": False,
        "required": [
            "text",
            "char_count",
            "pros",
            "cons",
            "keywords_used",
            "keyword_sources",
        ],
        "properties": {
            "text": {"type": "string"},
            "char_count": {"type": "integer"},
            "pros": {"type": "array", "items": {"type": "string"}},
            "cons": {"type": "array", "items": {"type": "string"}},
            "keywords_used": {"type": "array", "items": {"type": "string"}},
            "keyword_sources": {"type": "array", "items": {"type": "string"}},
        },
    }

    keyword_source_required = ["source_id", "source_url", "content_type"]
    if keyword_source_excerpt_required:
        keyword_source_required.append("excerpt")

    keyword_source_schema = {
        "type": "object",
        "additionalProperties": False,
        "required": keyword_source_required,
        "properties": {
            "source_id": {"type": "string"},
            "source_url": {"type": "string"},
            "content_type": {"type": "string"},
            "excerpt": {"type": "string"},
        },
    }

    template_review_schema = {
        "type": "object",
        "additionalProperties": False,
        "required": [
            "template_type",
            "variants",
            "keyword_sources",
            "strengthen_points",
        ],
        "properties": {
            "template_type": {"type": "string"},
            "variants": {
                "type": "array",
                "items": variant_schema,
                "minItems": variant_count,
                "maxItems": variant_count,
            },
            "keyword_sources": {
                "type": "array",
                "items": keyword_source_schema,
            },
            "strengthen_points": {
                "type": "array",
                "items": {"type": "string"},
            },
        },
    }

    properties = {
        "scores": {
            "type": "object",
            "additionalProperties": False,
            "required": score_required,
            "properties": score_properties,
        },
        "top3": {
            "type": "array",
            "items": issue_schema,
            "minItems": 1,
            "maxItems": top3_max_items,
        },
    }

    required = ["scores", "top3"]
    if include_rewrites:
        properties["rewrites"] = {
            "type": "array",
            "items": {"type": "string"},
            "minItems": 1,
            "maxItems": settings.es_rewrite_count,
        }
        required.append("rewrites")

    if include_section_feedbacks:
        properties["section_feedbacks"] = {
            "type": "array",
            "items": section_feedback_schema,
            "minItems": 1,
        }
        required.append("section_feedbacks")

    if include_template_review:
        properties["template_review"] = template_review_schema
        required.append("template_review")

    return {
        "name": "es_review_response",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "required": required,
            "properties": properties,
        },
    }


DIFFICULTY_LEVELS = {"easy", "medium", "hard"}


def _normalize_difficulty(value: Optional[str]) -> Optional[str]:
    if not value:
        return None
    normalized = value.strip().lower()
    mapping = {
        "easy": "easy",
        "medium": "medium",
        "hard": "hard",
        "ç°¡å˜": "easy",
        "æ˜“ã—ã„": "easy",
        "ä¸­": "medium",
        "æ™®é€š": "medium",
        "é›£ã—ã„": "hard",
        "é›£": "hard",
    }
    return mapping.get(
        normalized, normalized if normalized in DIFFICULTY_LEVELS else None
    )


def _parse_issues(items: list[dict], max_items: int) -> list[Issue]:
    issues: list[Issue] = []
    for item in items[:max_items]:
        issues.append(
            Issue(
                category=item.get("category", "ãã®ä»–"),
                issue=item.get("issue", ""),
                suggestion=item.get("suggestion", ""),
                difficulty=_normalize_difficulty(item.get("difficulty")) or "medium",
            )
        )
    return issues


def _build_review_cache_key(
    request: ReviewRequest,
    rag_status: Optional[dict],
    rewrite_count: int,
    context_length: Optional[int] = None,
) -> str:
    template_payload = (
        request.template_request.model_dump() if request.template_request else None
    )
    section_data_payload = (
        [s.model_dump() for s in request.section_data] if request.section_data else None
    )
    parts = [
        "es_review_v2",
        request.review_mode,
        request.content,
        request.style,
        str(request.is_paid),
        str(rewrite_count),
        str(context_length or ""),
        request.section_id or "",
        request.section_title or "",
        str(request.section_char_limit or ""),
        ",".join(request.sections or []),
        (
            json.dumps(section_data_payload, ensure_ascii=False)
            if section_data_payload
            else ""
        ),
        json.dumps(template_payload, ensure_ascii=False) if template_payload else "",
        request.company_id or "",
        str(request.has_company_rag),
    ]
    if rag_status:
        parts.append(str(rag_status.get("last_updated") or ""))
        parts.append(str(rag_status.get("total_chunks") or ""))
    return build_cache_key(*parts)


async def review_section_with_template(
    request: ReviewRequest,
    rag_context: str,
    rag_sources: list[dict],
    company_rag_available: bool,
    progress_queue: "asyncio.Queue | None" = None,
) -> ReviewResponse:
    """
    Review a single ES section using template-based prompts.

    This provides template-specific feedback with:
    - Pattern variants with pros/cons
    - Company keyword extraction from RAG
    - Character limit enforcement
    - Optional strengthen points

    Uses a retry loop to ensure output validation passes.
    When progress_queue is provided, streams LLM progress on the first attempt.
    """
    template_request = request.template_request
    if not template_request:
        raise ValueError("template_request is required")

    template_type = template_request.template_type
    if template_type not in TEMPLATE_DEFS:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown template type: {template_type}. Available: {list(TEMPLATE_DEFS.keys())}",
        )

    template_def = TEMPLATE_DEFS[template_type]
    keyword_count = template_def["keyword_count"]

    # Character limits
    char_min = template_request.char_min
    char_max = template_request.char_max

    # Check if template requires company RAG but none available
    if template_def["requires_company_rag"] and not company_rag_available:
        print(
            f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âš ï¸ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ {template_type} ã¯ RAG å¿…é ˆã ãŒåˆ©ç”¨ä¸å¯ - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—ã§ç¶šè¡Œ"
        )
        # Set keyword_count to 0 if no RAG available
        keyword_count = 0

    # Determine rewrite_count for template review
    rewrite_count = min(
        request.rewrite_count,
        settings.es_rewrite_count if request.is_paid else 1,
    )

    # Build prompts (apply safety margin to reduce overflow risk)
    prompt_char_min = char_min
    prompt_char_max = char_max
    if char_max:
        safe_max = int(char_max * 0.90)
        if char_min:
            safe_max = max(char_min, safe_max)
        if safe_max > 0:
            prompt_char_max = min(char_max, safe_max)

    system_prompt, user_prompt = build_template_prompt(
        template_type=template_type,
        company_name=template_request.company_name,
        industry=template_request.industry,
        question=template_request.question,
        answer=template_request.answer,
        char_min=prompt_char_min,
        char_max=prompt_char_max,
        rag_sources=rag_sources,
        rag_context=rag_context,
        keyword_count=keyword_count,
        has_rag=company_rag_available,
        intern_name=template_request.intern_name,
        role_name=template_request.role_name,
        rewrite_count=rewrite_count,
    )

    # Retry loop for validation
    # Optimize retries and tokens based on rewrite_count
    if rewrite_count == 1:
        max_retries = min(2, settings.es_template_max_retries)
        template_max_tokens = 2500  # 1 variant: ~400-800 chars + JSON structure
    else:
        max_retries = settings.es_template_max_retries
        template_max_tokens = 6000  # 3 variants: ~1200-2400 chars total + JSON
    retry_reason = ""
    last_template_review_data = None  # Track for conditional retry

    # Estimated max output chars for progress calculation
    estimated_max_chars = template_max_tokens * 3  # rough chars-per-token estimate

    for attempt in range(max_retries):
        # Add retry reason if not first attempt
        current_user_prompt = user_prompt
        if retry_reason:
            current_user_prompt += (
                f"\n\nã€å‰å›ã®ã‚¨ãƒ©ãƒ¼ - ä»¥ä¸‹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‘\n{retry_reason}"
            )

        print(
            f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ {template_type} è©¦è¡Œ {attempt + 1}/{max_retries}"
        )

        # First attempt: use streaming for real-time progress
        if attempt == 0 and progress_queue is not None:
            def _on_chunk(chunk: str, accumulated_len: int) -> None:
                # Calculate progress: 35% -> 85% during LLM streaming
                progress = 35 + int(50 * min(accumulated_len / estimated_max_chars, 1.0))
                try:
                    progress_queue.put_nowait(("progress", {
                        "step": "llm_review",
                        "progress": progress,
                        "label": "AIãŒæ·»å‰Šä¸­...",
                        "subLabel": f"{accumulated_len}æ–‡å­—ç”Ÿæˆæ¸ˆã¿",
                    }))
                except asyncio.QueueFull:
                    pass  # Skip if queue is full

            llm_result = await call_llm_streaming(
                system_prompt=system_prompt,
                user_message=current_user_prompt,
                max_tokens=template_max_tokens,
                temperature=0.4,
                feature="es_review",
                on_chunk=_on_chunk,
            )
        else:
            # Retries: use blocking call (faster, no streaming needed)
            llm_result = await call_llm_with_error(
                system_prompt=system_prompt,
                user_message=current_user_prompt,
                max_tokens=template_max_tokens,
                temperature=0.4,  # Slightly higher for variety
                feature="es_review",
                response_format="json_schema",
                json_schema=build_es_review_schema(
                    require_company_connection=company_rag_available,
                    include_template_review=True,
                    include_section_feedbacks=False,
                    include_rewrites=False,
                    top3_max_items=2,
                    keyword_source_excerpt_required=False,
                    variant_count=rewrite_count,
                ),
                use_responses_api=True,
                retry_on_parse=True,
                parse_retry_instructions="å¿…ãšæœ‰åŠ¹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ã§ã™ã€‚",
                disable_fallback=True,
            )

        if not llm_result.success:
            error = llm_result.error
            raise HTTPException(
                status_code=503,
                detail={
                    "error": (
                        error.message if error else "AIå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
                    ),
                    "error_type": error.error_type if error else "unknown",
                    "provider": error.provider if error else "unknown",
                    "detail": error.detail if error else "",
                },
            )

        data = llm_result.data
        if data is None:
            retry_reason = (
                "AIã‹ã‚‰ã®å¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœ‰åŠ¹ãªJSONã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"
            )
            continue

        # Check for template_review in response
        template_review_data = data.get("template_review")
        if not template_review_data:
            retry_reason = "template_review ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå‡ºåŠ›ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            continue

        # Validate output
        is_valid, error_reason = validate_template_output(
            template_review_data,
            char_min=char_min,
            char_max=char_max,
            rewrite_count=rewrite_count,
        )

        # Attempt a single repair for char limit failures (both over and under limits)
        if (not is_valid) and error_reason and "æ–‡å­—" in error_reason:
            # Parse specific character errors for targeted feedback
            variants = template_review_data.get("variants", [])
            variant_errors = parse_validation_errors(variants, char_min, char_max)

            if variant_errors:
                # Build targeted adjustment prompt with specific deltas
                adjustment_instructions = build_char_adjustment_prompt(
                    variant_errors, char_min, char_max
                )
                repair_prompt = f"""{adjustment_instructions}

å¯¾è±¡JSON:
{json.dumps(data, ensure_ascii=False)}

JSONä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚"""
            else:
                # Fallback to generic repair if no specific errors parsed
                repair_prompt = f"""ä»¥ä¸‹ã®JSONã®å½¢å¼ã¯ç¶­æŒã—ãŸã¾ã¾ã€variants[*].text ã‚’æŒ‡å®šæ–‡å­—æ•°å†…ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
- æ–‡å­—æ•°åˆ¶ç´„: {char_min or 0}ã€œ{char_max or 'ç„¡åˆ¶é™'} æ–‡å­—
- ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ§‹é€ ã¯ä¸€åˆ‡å¤‰æ›´ã—ãªã„
- JSONä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„

å¯¾è±¡JSON:
{json.dumps(data, ensure_ascii=False)}
"""

            repair_result = await call_llm_with_error(
                system_prompt="ã‚ãªãŸã¯JSONä¿®å¾©ã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšJSONã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
                user_message=repair_prompt,
                max_tokens=4000,  # æ–‡å­—æ•°èª¿æ•´æ™‚ã‚‚ä½™è£•ã‚’æŒã£ã¦è¨­å®š
                temperature=0.2,
                feature="es_review",
                disable_fallback=True,
            )

            if repair_result.success and repair_result.data:
                data = repair_result.data
                template_review_data = (
                    data.get("template_review") or template_review_data
                )
                is_valid, error_reason = validate_template_output(
                    template_review_data,
                    char_min=char_min,
                    char_max=char_max,
                    rewrite_count=rewrite_count,
                )

        if is_valid:
            # Build response
            try:
                # Parse scores
                scores_data = data.get("scores", {})
                scores = Score(
                    logic=max(1, min(5, scores_data.get("logic", 3))),
                    specificity=max(1, min(5, scores_data.get("specificity", 3))),
                    passion=max(1, min(5, scores_data.get("passion", 3))),
                    company_connection=(
                        max(1, min(5, scores_data.get("company_connection", 3)))
                        if company_rag_available
                        else None
                    ),
                    readability=max(1, min(5, scores_data.get("readability", 3))),
                )

                # Parse top3 (1-2 issues for section)
                top3_data = data.get("top3", [])
                top3 = _parse_issues(top3_data, 2)
                if not top3:
                    top3 = [
                        Issue(
                            category="ãã®ä»–",
                            issue="æ”¹å–„ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                            suggestion="å…¨ä½“çš„ãªè¦‹ç›´ã—ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„",
                            difficulty="medium",
                        )
                    ]

                # Get rewrites from data or template variants
                rewrites_data = data.get("rewrites", [])
                if isinstance(rewrites_data, str):
                    rewrites_data = [rewrites_data]
                if not rewrites_data:
                    # Use template variants as rewrites
                    rewrites_data = [
                        v.get("text", "")
                        for v in template_review_data.get("variants", [])
                    ]
                rewrites = rewrites_data[:rewrite_count]

                # Parse template review
                variants_data = template_review_data.get("variants", [])
                variants = [
                    TemplateVariant(
                        text=v.get("text", ""),
                        char_count=len(v.get("text", "")),
                        pros=v.get("pros", []),
                        cons=v.get("cons", []),
                        keywords_used=v.get("keywords_used", []),
                        keyword_sources=v.get("keyword_sources", []),
                    )
                    for v in variants_data
                ]

                # Parse keyword sources
                keyword_sources_data = template_review_data.get("keyword_sources", [])
                keyword_sources = [
                    TemplateSource(
                        source_id=src.get("source_id", ""),
                        source_url=src.get("source_url", ""),
                        content_type=src.get("content_type", ""),
                        excerpt=src.get("excerpt"),
                    )
                    for src in keyword_sources_data
                ]

                # Merge RAG sources if keyword_sources is empty
                if not keyword_sources and rag_sources:
                    keyword_sources = [
                        TemplateSource(
                            source_id=src.get("source_id", ""),
                            source_url=src.get("source_url", ""),
                            content_type=src.get("content_type", ""),
                            excerpt=src.get("excerpt"),
                        )
                        for src in rag_sources
                    ]

                # Get strengthen points if required
                strengthen_points = None
                if template_def.get("require_strengthen_points"):
                    strengthen_points = template_review_data.get(
                        "strengthen_points", []
                    )

                template_review = TemplateReview(
                    template_type=template_type,
                    variants=variants,
                    keyword_sources=keyword_sources,
                    strengthen_points=strengthen_points,
                )

                print(f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âœ… è©¦è¡Œ {attempt + 1} ã§æˆåŠŸ")
                return ReviewResponse(
                    scores=scores,
                    top3=top3,
                    rewrites=rewrites,
                    section_feedbacks=None,
                    template_review=template_review,
                )

            except Exception as e:
                print(f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âŒ è©¦è¡Œ {attempt + 1} è§£æã‚¨ãƒ©ãƒ¼: {e}")
                retry_reason = f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
                continue
        else:
            print(
                f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âš ï¸ è©¦è¡Œ {attempt + 1} æ¤œè¨¼å¤±æ•—: {error_reason}"
            )
            # Track for potential conditional retry
            last_template_review_data = template_review_data

            # If character limit error, add specific adjustment instructions
            if "æ–‡å­—" in error_reason:
                variants = template_review_data.get("variants", [])
                variant_errors = parse_validation_errors(variants, char_min, char_max)
                if variant_errors:
                    adjustment_prompt = build_char_adjustment_prompt(
                        variant_errors, char_min, char_max
                    )
                    retry_reason = adjustment_prompt
                else:
                    retry_reason = error_reason
            else:
                retry_reason = error_reason

    # Main retries exhausted - attempt conditional retry if enabled and worthwhile
    if (
        settings.es_enable_conditional_retry
        and last_template_review_data
        and "æ–‡å­—" in retry_reason
    ):
        should_retry, failing_indices = should_attempt_conditional_retry(
            last_template_review_data, char_min, char_max, rewrite_count=rewrite_count
        )

        if should_retry:
            print(
                f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] ğŸ”„ æ¡ä»¶ä»˜ããƒªãƒˆãƒ©ã‚¤: {len(failing_indices)}/{rewrite_count} ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ä¿®æ­£"
            )

            # Build targeted repair prompt
            repair_prompt = build_targeted_variant_repair_prompt(
                last_template_review_data, failing_indices, char_min, char_max
            )

            repair_result = await call_llm_with_error(
                system_prompt="ã‚ãªãŸã¯JSONä¿®å¾©ã®å°‚é–€å®¶ã§ã™ã€‚æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ–‡å­—æ•°ã®ã¿ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚",
                user_message=repair_prompt,
                max_tokens=2000,  # Reduced - only fixing specific variants
                temperature=0.2,
                feature="es_review",
                disable_fallback=True,
            )

            if repair_result.success and repair_result.data:
                repaired_data = repair_result.data
                repaired_template = (
                    repaired_data.get("template_review") or repaired_data
                )

                # Validate the repaired output
                is_valid, repair_error = validate_template_output(
                    repaired_template,
                    char_min=char_min,
                    char_max=char_max,
                    rewrite_count=rewrite_count,
                )

                if is_valid:
                    print("[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âœ… æ¡ä»¶ä»˜ããƒªãƒˆãƒ©ã‚¤æˆåŠŸ")

                    # Build and return successful response
                    scores_data = data.get("scores", {}) if data else {}
                    scores = Score(
                        logic=max(1, min(5, scores_data.get("logic", 3))),
                        specificity=max(1, min(5, scores_data.get("specificity", 3))),
                        passion=max(1, min(5, scores_data.get("passion", 3))),
                        company_connection=(
                            max(1, min(5, scores_data.get("company_connection", 3)))
                            if company_rag_available
                            else None
                        ),
                        readability=max(1, min(5, scores_data.get("readability", 3))),
                    )

                    top3_data = data.get("top3", []) if data else []
                    top3 = _parse_issues(top3_data, 2)
                    if not top3:
                        top3 = [
                            Issue(
                                category="ãã®ä»–",
                                issue="æ”¹å–„ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                                suggestion="å…¨ä½“çš„ãªè¦‹ç›´ã—ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„",
                                difficulty="medium",
                            )
                        ]

                    variants_data = repaired_template.get("variants", [])
                    variants = [
                        TemplateVariant(
                            text=v.get("text", ""),
                            char_count=len(v.get("text", "")),
                            pros=v.get("pros", []),
                            cons=v.get("cons", []),
                            keywords_used=v.get("keywords_used", []),
                            keyword_sources=v.get("keyword_sources", []),
                        )
                        for v in variants_data
                    ]

                    keyword_sources_data = repaired_template.get("keyword_sources", [])
                    keyword_sources = [
                        TemplateSource(
                            source_id=src.get("source_id", ""),
                            source_url=src.get("source_url", ""),
                            content_type=src.get("content_type", ""),
                            excerpt=src.get("excerpt"),
                        )
                        for src in keyword_sources_data
                    ]

                    if not keyword_sources and rag_sources:
                        keyword_sources = [
                            TemplateSource(
                                source_id=src.get("source_id", ""),
                                source_url=src.get("source_url", ""),
                                content_type=src.get("content_type", ""),
                                excerpt=src.get("excerpt"),
                            )
                            for src in rag_sources
                        ]

                    strengthen_points = None
                    if template_def.get("require_strengthen_points"):
                        strengthen_points = repaired_template.get(
                            "strengthen_points", []
                        )

                    template_review = TemplateReview(
                        template_type=template_type,
                        variants=variants,
                        keyword_sources=keyword_sources,
                        strengthen_points=strengthen_points,
                    )

                    rewrites = [v.get("text", "") for v in variants_data]

                    return ReviewResponse(
                        scores=scores,
                        top3=top3,
                        rewrites=rewrites,
                        section_feedbacks=None,
                        template_review=template_review,
                    )
                else:
                    print(
                        f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âš ï¸ æ¡ä»¶ä»˜ããƒªãƒˆãƒ©ã‚¤ã‚‚å¤±æ•—: {repair_error}"
                    )

    # All retries exhausted
    record_parse_failure("es_review_template", retry_reason)
    raise HTTPException(
        status_code=422,
        detail={
            "error": "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‡ºåŠ›ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¡ä»¶ã‚’æº€ãŸã™å‡ºåŠ›ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
            "error_type": "validation",
            "provider": "template_review",
            "detail": retry_reason,
        },
    )


async def review_section(
    request: ReviewRequest, company_context: str, company_rag_available: bool
) -> ReviewResponse:
    """
    Review a single ES section (question).

    This provides focused feedback on one specific question/section.
    """
    # Inject gakuchika context if available
    gakuchika_context_section = ""
    if request.gakuchika_context:
        gakuchika_context_section = f"""

**ã‚¬ã‚¯ãƒã‚«æ·±æ˜ã‚Šæƒ…å ±:**
ä»¥ä¸‹ã¯ã‚¬ã‚¯ãƒã‚«ï¼ˆå­¦ç”Ÿæ™‚ä»£ã«åŠ›ã‚’å…¥ã‚ŒãŸã“ã¨ï¼‰ã®æ·±æ˜ã‚Šã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã§ã™ã€‚
ESã®æ·»å‰Šã«ãŠã„ã¦ã€ã“ã‚Œã‚‰ã®çµŒé¨“ã‚„å¼·ã¿ãŒæ´»ã‹ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åæ˜ ã—ã¦ãã ã•ã„ã€‚

{request.gakuchika_context}
"""

    # Build scoring criteria (same as full review)
    score_criteria = """1. scores (å„1-5ç‚¹):
   - logic: è«–ç†ã®ä¸€è²«æ€§ï¼ˆä¸»å¼µã¨æ ¹æ‹ ã®æ•´åˆæ€§ã€å› æœé–¢ä¿‚ã®æ˜ç¢ºã•ï¼‰
   - specificity: å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã€å›ºæœ‰åè©ã®ä½¿ç”¨ï¼‰
   - passion: ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦ï¼ˆãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®èª¬å¾—åŠ›ï¼‰"""

    if company_rag_available:
        score_criteria += """
   - company_connection: ä¼æ¥­æ¥ç¶šï¼ˆä¼æ¥­æƒ…å ±ã«åŸºã¥ã„ã¦è©•ä¾¡ï¼‰
     * ä¼æ¥­ã®å…·ä½“çš„ãªäº‹æ¥­å†…å®¹ãƒ»å–ã‚Šçµ„ã¿ã¸ã®è¨€åŠãŒã‚ã‚‹ã‹
     * ä¼æ¥­ã®ä¾¡å€¤è¦³ãƒ»æ–‡åŒ–ã¨è‡ªèº«ã®çµŒé¨“ãƒ»ä¾¡å€¤è¦³ã®æ¥ç‚¹ã‚’ç¤ºã—ã¦ã„ã‚‹ã‹"""

    score_criteria += """
   - readability: èª­ã¿ã‚„ã™ã•ï¼ˆæ–‡ç« ã®æ˜ç­ã•ã€æ§‹æˆã®åˆ†ã‹ã‚Šã‚„ã™ã•ï¼‰"""

    # Build rewrite instruction
    style_instructions = {
        "ãƒãƒ©ãƒ³ã‚¹": "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã€èª­ã¿ã‚„ã™ã„æ–‡ç« ã«",
        "å …ã‚": "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§å …å®Ÿãªå°è±¡ã®æ–‡ç« ã«",
        "å€‹æ€§å¼·ã‚": "å€‹æ€§ã¨ç‹¬è‡ªæ€§ãŒéš›ç«‹ã¤æ–‡ç« ã«",
        "çŸ­ã": "ç°¡æ½”ã§ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªæ–‡ç« ã«",
        "ç†±æ„å¼·ã‚": "ç†±æ„ã¨æ„æ¬²ãŒå¼·ãä¼ã‚ã‚‹æ–‡ç« ã«",
        "çµè«–å…ˆå‡ºã—": "çµè«–ã‚’å…ˆã«è¿°ã¹ã€æ ¹æ‹ ã‚’å¾Œã‹ã‚‰ç¤ºã™æ§‹æˆã«",
        "å…·ä½“ä¾‹å¼·ã‚": "å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„æ•°å€¤ã‚’å¢—ã‚„ã—ãŸæ–‡ç« ã«",
        "ç«¯çš„": "ç«¯çš„ã§è¦ç‚¹ã‚’æŠ¼ã•ãˆãŸæ–‡ç« ã«",
    }
    rewrite_instruction = style_instructions.get(
        request.style, "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ–‡ç« ã«"
    )

    # Character limit instruction
    char_limit_instruction = ""
    if request.section_char_limit:
        char_limit_instruction = (
            f"   - æ–‡å­—æ•°åˆ¶é™: {request.section_char_limit}æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„"
        )

    system_prompt = f"""ã‚ãªãŸã¯ESï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ãƒ¼ãƒˆï¼‰æ·»å‰Šã®å°‚é–€å®¶ã§ã™ã€‚
å°±æ´»ç”Ÿã®ESã®**ç‰¹å®šã®è¨­å•**ã‚’æ·»å‰Šã—ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

è¨­å•ã‚¿ã‚¤ãƒˆãƒ«: ã€Œ{request.section_title or 'ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰'}ã€
{f'æ–‡å­—æ•°åˆ¶é™: {request.section_char_limit}æ–‡å­—' if request.section_char_limit else ''}

ä»¥ä¸‹ã®è¦³ç‚¹ã§è©•ä¾¡ã—ã€å¿…ãšJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{score_criteria}

2. top3: æ”¹å–„ã™ã¹ãç‚¹ï¼ˆ1ã€œ2ç‚¹ï¼‰
   - category: è©•ä¾¡è»¸ã®åå‰ï¼ˆè«–ç†ã€å…·ä½“æ€§ã€ç†±æ„ã€{"ä¼æ¥­æ¥ç¶šã€" if company_rag_available else ""}èª­ã¿ã‚„ã™ã•ï¼‰
   - issue: å…·ä½“çš„ãªå•é¡Œç‚¹ï¼ˆæ–‡ç« ã®ã©ã“ãŒã€ãªãœå•é¡Œã‹ï¼‰
   - suggestion: å®Ÿè·µçš„ãªæ”¹å–„æ¡ˆï¼ˆå…·ä½“çš„ã«ä½•ã‚’ã©ã†å¤‰ãˆã‚‹ã‹ï¼‰
   - difficulty: é›£æ˜“åº¦ï¼ˆeasy/medium/hardï¼‰
   {"â€»ä¼æ¥­æ¥ç¶šã®æŒ‡æ‘˜ã§ã¯ã€æä¾›ã•ã‚ŒãŸä¼æ¥­æƒ…å ±ã‚’å‚ç…§ã—ã¦å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’ç¤ºã—ã¦ãã ã•ã„" if company_rag_available else ""}

3. rewrites: æ”¹å–„ä¾‹ï¼ˆ1ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
   - ã‚¹ã‚¿ã‚¤ãƒ«ã€Œ{request.style}ã€ã«æ²¿ã£ã¦{rewrite_instruction}ãƒªãƒ©ã‚¤ãƒˆ
   - å…ƒã®æ–‡ç« ã®è‰¯ã„éƒ¨åˆ†ã¯æ´»ã‹ã—ã¤ã¤ã€å•é¡Œç‚¹ã‚’æ”¹å–„ã—ãŸæ–‡ç« 
{char_limit_instruction}
   {"- ä¼æ¥­æƒ…å ±ã«åŸºã¥ã„ã¦ã€ä¼æ¥­ã®äº‹æ¥­å†…å®¹ã‚„ä¾¡å€¤è¦³ã¨çµã³ã¤ãè¡¨ç¾ã‚’è¿½åŠ " if company_rag_available else ""}

ã‚¹ã‚³ã‚¢ã¯å³ã—ã‚ã«ä»˜ã‘ã¦ãã ã•ã„ï¼ˆå¹³å‡3ç‚¹ç¨‹åº¦ï¼‰ã€‚
ã“ã®è¨­å•ã«ç‰¹åŒ–ã—ãŸå…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšæœ‰åŠ¹ãªJSONã§å›ç­”ï¼‰:
{{
  "scores": {{"logic": 3, "specificity": 3, "passion": 3, "readability": 3{', "company_connection": 3' if company_rag_available else ''}}},
  "top3": [
    {{"category": "...", "issue": "...", "suggestion": "...", "difficulty": "easy"}}
  ],
  "rewrites": ["ãƒªãƒ©ã‚¤ãƒˆæ¡ˆ"]
}}"""

    # Build user message
    user_message = f"""ä»¥ä¸‹ã®è¨­å•ã¸ã®å›ç­”ã‚’æ·»å‰Šã—ã¦ãã ã•ã„ï¼š

**è¨­å•**: {request.section_title or 'ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰'}
{f'**æ–‡å­—æ•°åˆ¶é™**: {request.section_char_limit}æ–‡å­—' if request.section_char_limit else ''}

**å›ç­”å†…å®¹**:
{request.content}"""

    if company_context:
        user_message = f"""ä»¥ä¸‹ã®è¨­å•ã¸ã®å›ç­”ã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚

**ä¼æ¥­æƒ…å ±ï¼ˆRAGã‹ã‚‰å–å¾—ï¼‰:**
{company_context}
{gakuchika_context_section}
**è¨­å•**: {request.section_title or 'ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰'}
{f'**æ–‡å­—æ•°åˆ¶é™**: {request.section_char_limit}æ–‡å­—' if request.section_char_limit else ''}

**å›ç­”å†…å®¹**:
{request.content}"""
    else:
        # No company context, but may have gakuchika context
        if gakuchika_context_section:
            user_message = f"""ä»¥ä¸‹ã®è¨­å•ã¸ã®å›ç­”ã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚
{gakuchika_context_section}
**è¨­å•**: {request.section_title or 'ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰'}
{f'**æ–‡å­—æ•°åˆ¶é™**: {request.section_char_limit}æ–‡å­—' if request.section_char_limit else ''}

**å›ç­”å†…å®¹**:
{request.content}"""

    # Call LLM
    llm_result = await call_llm_with_error(
        system_prompt=system_prompt,
        user_message=user_message,
        max_tokens=2000,  # Less tokens needed for single section
        temperature=0.3,
        feature="es_review",
        response_format="json_schema",
        json_schema=build_es_review_schema(
            require_company_connection=company_rag_available,
            include_template_review=False,
            include_section_feedbacks=False,
        ),
        use_responses_api=True,
        retry_on_parse=True,
        parse_retry_instructions="å¿…ãšæœ‰åŠ¹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ã§ã™ã€‚",
        disable_fallback=True,
    )

    if not llm_result.success:
        error = llm_result.error
        raise HTTPException(
            status_code=503,
            detail={
                "error": error.message if error else "AIå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "error_type": error.error_type if error else "unknown",
                "provider": error.provider if error else "unknown",
                "detail": error.detail if error else "",
            },
        )

    data = llm_result.data
    if data is None:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AIã‹ã‚‰ã®å¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "error_type": "parse",
                "provider": "unknown",
                "detail": "Empty response from LLM",
            },
        )

    try:
        # Parse response
        scores_data = data.get("scores", {})
        scores = Score(
            logic=max(1, min(5, scores_data.get("logic", 3))),
            specificity=max(1, min(5, scores_data.get("specificity", 3))),
            passion=max(1, min(5, scores_data.get("passion", 3))),
            company_connection=(
                max(1, min(5, scores_data.get("company_connection", 3)))
                if company_rag_available
                else None
            ),
            readability=max(1, min(5, scores_data.get("readability", 3))),
        )

        # Get 1-2 issues for section review
        top3_data = data.get("top3", [])
        top3 = _parse_issues(top3_data, 2)

        # Ensure we have at least 1 issue
        if not top3:
            top3 = [
                Issue(
                    category="ãã®ä»–",
                    issue="æ”¹å–„ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    suggestion="å…¨ä½“çš„ãªè¦‹ç›´ã—ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„",
                    difficulty="medium",
                )
            ]

        # Get single rewrite
        rewrites_data = data.get("rewrites", [])
        if isinstance(rewrites_data, str):
            rewrites_data = [rewrites_data]
        rewrites = rewrites_data[:1] if rewrites_data else [request.content]

        return ReviewResponse(
            scores=scores,
            top3=top3,
            rewrites=rewrites,
            section_feedbacks=None,  # Not used in section mode
        )

    except Exception as e:
        print(f"[ESæ·»å‰Š/ã‚»ã‚¯ã‚·ãƒ§ãƒ³] âŒ LLMå¿œç­”è§£æå¤±æ•—: {e}")
        record_parse_failure("es_review_section", str(e))
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                "error_type": "parse",
                "provider": "unknown",
                "detail": str(e),
            },
        )


@router.post("/review", response_model=ReviewResponse)
async def review_es(request: ReviewRequest):
    """
    Review ES content and provide scores, improvement suggestions, and rewrites.

    This endpoint supports two modes:
    - review_mode="full": Review entire ES (default)
    - review_mode="section": Review a single question/section

    Scoring axes (SPEC Section 16.2):
    - è«–ç† (logic): è«–ç†ã®ä¸€è²«æ€§
    - å…·ä½“æ€§ (specificity): å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰
    - ç†±æ„ (passion): ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦
    - ä¼æ¥­æ¥ç¶š (company_connection): ä¼æ¥­ã¨ã®æ¥ç¶šåº¦ï¼ˆRAGå–å¾—æ™‚ã®ã¿ï¼‰
    - èª­ã¿ã‚„ã™ã• (readability): æ–‡ç« ã®èª­ã¿ã‚„ã™ã•

    The caller (Next.js API) is responsible for:
    - Authentication
    - Credit checking and consumption
    - Rate limiting
    """
    if not request.content or len(request.content.strip()) < 10:
        raise HTTPException(
            status_code=400,
            detail="ESã®å†…å®¹ãŒçŸ­ã™ãã¾ã™ã€‚ã‚‚ã†å°‘ã—è©³ã—ãæ›¸ã„ã¦ã‹ã‚‰æ·»å‰Šã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚",
        )

    # Validate review_mode
    if request.review_mode not in ("full", "section"):
        raise HTTPException(
            status_code=400,
            detail="review_modeã¯ 'full' ã¾ãŸã¯ 'section' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„",
        )

    # Validate style based on plan
    available_styles = PAID_STYLES if request.is_paid else FREE_STYLES
    if request.style not in available_styles:
        raise HTTPException(
            status_code=400, detail=f"åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚¿ã‚¤ãƒ«: {', '.join(available_styles)}"
        )

    # Cap rewrite count based on plan
    rewrite_count = min(request.rewrite_count, settings.es_rewrite_count if request.is_paid else 1)

    # Check and fetch company RAG context if company_id is provided
    company_context = ""
    company_rag_available = request.has_company_rag
    rag_status = None
    context_length = get_dynamic_context_length(request.content)

    if request.company_id and not company_rag_available:
        # Check if company has RAG data
        company_rag_available = has_company_rag(request.company_id)

    if request.company_id and company_rag_available:
        # Check RAG status for richer logging
        rag_status = get_company_rag_status(request.company_id)

    # Cache lookup (after rag status is known)
    cache = get_es_review_cache()
    cache_key = _build_review_cache_key(
        request, rag_status, rewrite_count, context_length
    )
    if cache:
        cached = await cache.get_review(cache_key)
        if isinstance(cached, dict):
            return cached

    if request.company_id and company_rag_available:
        # Use enhanced context fetching with hybrid search
        # This provides better results by combining semantic and keyword search
        company_context = await get_enhanced_context_for_review(
            company_id=request.company_id,
            es_content=request.content,
            max_context_length=context_length,
        )

        # Validate context before logging success (Bug #7 fix)
        min_context_length = max(0, settings.rag_min_context_chars)
        if company_context and len(company_context) >= min_context_length:
            print(f"[ESæ·»å‰Š] âœ… RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å®Œäº† ({len(company_context)}æ–‡å­—)")
            print(
                f"[ESæ·»å‰Š] RAGçŠ¶æ³: å…¨{rag_status.get('total_chunks', 0)}ãƒãƒ£ãƒ³ã‚¯ "
                f"(æ–°å’: {rag_status.get('new_grad_recruitment_chunks', 0)}, "
                f"ä¸­é€”: {rag_status.get('midcareer_recruitment_chunks', 0)}, "
                f"ä¼æ¥­HP: {rag_status.get('corporate_site_chunks', 0)}, "
                f"IR: {rag_status.get('ir_materials_chunks', 0)}, "
                f"ç¤¾é•·: {rag_status.get('ceo_message_chunks', 0)}, "
                f"ç¤¾å“¡INT: {rag_status.get('employee_interviews_chunks', 0)}, "
                f"PR: {rag_status.get('press_release_chunks', 0)}, "
                f"CSR: {rag_status.get('csr_sustainability_chunks', 0)}, "
                f"ä¸­è¨ˆ: {rag_status.get('midterm_plan_chunks', 0)})"
            )
        else:
            context_len = len(company_context) if company_context else 0
            print(
                f"[ESæ·»å‰Š] âš ï¸ RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸è¶³ ({context_len}æ–‡å­— < {min_context_length}æ–‡å­—ã®é–¾å€¤)"
            )
            company_context = ""
            company_rag_available = False

        record_rag_context(
            company_id=request.company_id,
            context_length=len(company_context),
            source_count=(
                rag_status.get("total_chunks", 0) if company_rag_available else 0
            ),
        )

    # Branch based on review_mode
    if request.review_mode == "section":
        print(
            f"[ESæ·»å‰Š/ã‚»ã‚¯ã‚·ãƒ§ãƒ³] è¨­å•ã€Œ{request.section_title or '(ç„¡é¡Œ)'}ã€ã‚’æ·»å‰Šä¸­ "
            f"({len(request.content)}æ–‡å­—)"
        )

        # Check if template-based review is requested
        if request.template_request:
            print(
                f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ·»å‰Šé–‹å§‹: {request.template_request.template_type}"
            )

            # Fetch RAG context with sources for template review
            rag_context = ""
            rag_sources = []
            if request.company_id and company_rag_available:
                rag_context, rag_sources = (
                    await get_enhanced_context_for_review_with_sources(
                        company_id=request.company_id,
                        es_content=request.content,
                        max_context_length=context_length,
                    )
                )
                print(
                    f"[ESæ·»å‰Š/ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ] âœ… RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å®Œäº† ({len(rag_sources)}ã‚½ãƒ¼ã‚¹)"
                )
                if len(rag_context) < 200 or not rag_sources:
                    rag_context = ""
                    rag_sources = []
                    company_rag_available = False
                record_rag_context(
                    company_id=request.company_id,
                    context_length=len(rag_context),
                    source_count=len(rag_sources),
                )

            result = await review_section_with_template(
                request=request,
                rag_context=rag_context,
                rag_sources=rag_sources,
                company_rag_available=company_rag_available,
            )
            record_es_scores(result.scores.model_dump())
            if cache:
                await cache.set_review(cache_key, result.model_dump())
            return result

        # Standard section review (no template)
        result = await review_section(
            request=request,
            company_context=company_context,
            company_rag_available=company_rag_available,
        )
        record_es_scores(result.scores.model_dump())
        if cache:
            await cache.set_review(cache_key, result.model_dump())
        return result

    # Full ES review mode (default)
    print(f"[ESæ·»å‰Š] ESå…¨ä½“ã‚’æ·»å‰Šä¸­ ({len(request.content)}æ–‡å­—)")

    # Build scoring criteria based on RAG availability
    score_criteria = """1. scores (å„1-5ç‚¹):
   - logic: è«–ç†ã®ä¸€è²«æ€§ï¼ˆä¸»å¼µã¨æ ¹æ‹ ã®æ•´åˆæ€§ã€å› æœé–¢ä¿‚ã®æ˜ç¢ºã•ï¼‰
   - specificity: å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã€å›ºæœ‰åè©ã®ä½¿ç”¨ï¼‰
   - passion: ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦ï¼ˆãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®èª¬å¾—åŠ›ï¼‰"""

    if company_rag_available:
        score_criteria += """
   - company_connection: ä¼æ¥­æ¥ç¶šï¼ˆä¼æ¥­æƒ…å ±ã«åŸºã¥ã„ã¦è©•ä¾¡ï¼‰
     * ä¼æ¥­ã®å…·ä½“çš„ãªäº‹æ¥­å†…å®¹ãƒ»å–ã‚Šçµ„ã¿ã¸ã®è¨€åŠãŒã‚ã‚‹ã‹
     * ä¼æ¥­ã®ä¾¡å€¤è¦³ãƒ»æ–‡åŒ–ã¨è‡ªèº«ã®çµŒé¨“ãƒ»ä¾¡å€¤è¦³ã®æ¥ç‚¹ã‚’ç¤ºã—ã¦ã„ã‚‹ã‹
     * å¿—æœ›å‹•æ©ŸãŒä¼æ¥­ã®å®Ÿæ…‹ã«å³ã—ã¦ã„ã‚‹ã‹ï¼ˆè¡¨é¢çš„ãªæƒ…å ±ã§ã¯ãªãæ·±ã„ç†è§£ï¼‰
     * ã€Œãªãœã“ã®ä¼æ¥­ãªã®ã‹ã€ãŒæ˜ç¢ºã«ä¼ã‚ã‚‹ã‹"""

    score_criteria += """
   - readability: èª­ã¿ã‚„ã™ã•ï¼ˆæ–‡ç« ã®æ˜ç­ã•ã€æ§‹æˆã®åˆ†ã‹ã‚Šã‚„ã™ã•ï¼‰"""

    # Build rewrite instruction based on style
    style_instructions = {
        "ãƒãƒ©ãƒ³ã‚¹": "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã€èª­ã¿ã‚„ã™ã„æ–‡ç« ã«",
        "å …ã‚": "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§å …å®Ÿãªå°è±¡ã®æ–‡ç« ã«",
        "å€‹æ€§å¼·ã‚": "å€‹æ€§ã¨ç‹¬è‡ªæ€§ãŒéš›ç«‹ã¤æ–‡ç« ã«",
        "çŸ­ã": "ç°¡æ½”ã§ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªæ–‡ç« ã«",
        "ç†±æ„å¼·ã‚": "ç†±æ„ã¨æ„æ¬²ãŒå¼·ãä¼ã‚ã‚‹æ–‡ç« ã«",
        "çµè«–å…ˆå‡ºã—": "çµè«–ã‚’å…ˆã«è¿°ã¹ã€æ ¹æ‹ ã‚’å¾Œã‹ã‚‰ç¤ºã™æ§‹æˆã«",
        "å…·ä½“ä¾‹å¼·ã‚": "å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„æ•°å€¤ã‚’å¢—ã‚„ã—ãŸæ–‡ç« ã«",
        "ç«¯çš„": "ç«¯çš„ã§è¦ç‚¹ã‚’æŠ¼ã•ãˆãŸæ–‡ç« ã«",
    }

    rewrite_instruction = style_instructions.get(
        request.style, "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ–‡ç« ã«"
    )

    # Section feedback instruction (paid only)
    section_feedback_instruction = ""
    if request.is_paid and request.section_data:
        # Use section_data with char limits
        section_items = []
        for s in request.section_data:
            limit_note = f"ï¼ˆæ–‡å­—æ•°åˆ¶é™: {s.char_limit}æ–‡å­—ï¼‰" if s.char_limit else ""
            section_items.append(f"   - {s.title}{limit_note}")
        section_list = "\n".join(section_items)
        section_feedback_instruction = f"""
4. section_feedbacks: è¨­å•åˆ¥ã®æŒ‡æ‘˜ã¨æ”¹å–„ä¾‹
   ä»¥ä¸‹ã®å„è¨­å•ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ”¹å–„ç‚¹ã¨æ”¹å–„ä¾‹ã‚’æä¾›ã—ã¦ãã ã•ã„:
{section_list}
   - section_title: è¨­å•ã‚¿ã‚¤ãƒˆãƒ«
   - feedback: ãã®è¨­å•ã«ç‰¹åŒ–ã—ãŸæ”¹å–„ç‚¹ï¼ˆ100-150å­—ï¼‰
   - rewrite: æ”¹å–„ä¾‹ï¼ˆæ–‡å­—æ•°åˆ¶é™ãŒã‚ã‚‹å ´åˆã¯ãã®æ–‡å­—æ•°ä»¥å†…ã§ï¼‰"""
    elif request.is_paid and request.sections:
        section_list = "\n".join([f"   - {s}" for s in request.sections])
        section_feedback_instruction = f"""
4. section_feedbacks: è¨­å•åˆ¥ã®æŒ‡æ‘˜ï¼ˆ100-150å­—/è¨­å•ï¼‰
   ä»¥ä¸‹ã®å„è¨­å•ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„:
{section_list}
   - section_title: è¨­å•ã‚¿ã‚¤ãƒˆãƒ«
   - feedback: ãã®è¨­å•ã«ç‰¹åŒ–ã—ãŸæ”¹å–„ç‚¹ï¼ˆ100-150å­—ï¼‰"""

    system_prompt = f"""ã‚ãªãŸã¯ESï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ãƒ¼ãƒˆï¼‰æ·»å‰Šã®å°‚é–€å®¶ã§ã™ã€‚
å°±æ´»ç”Ÿã®ESã‚’æ·»å‰Šã—ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦³ç‚¹ã§è©•ä¾¡ã—ã€å¿…ãšJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{score_criteria}

2. top3: æ”¹å–„ã™ã¹ãä¸Šä½3ç‚¹
   - category: è©•ä¾¡è»¸ã®åå‰ï¼ˆè«–ç†ã€å…·ä½“æ€§ã€ç†±æ„ã€{"ä¼æ¥­æ¥ç¶šã€" if company_rag_available else ""}èª­ã¿ã‚„ã™ã•ï¼‰
   - issue: å…·ä½“çš„ãªå•é¡Œç‚¹ï¼ˆæ–‡ç« ã®ã©ã“ãŒã€ãªãœå•é¡Œã‹ï¼‰
   - suggestion: å®Ÿè·µçš„ãªæ”¹å–„æ¡ˆï¼ˆå…·ä½“çš„ã«ä½•ã‚’ã©ã†å¤‰ãˆã‚‹ã‹ï¼‰
   - difficulty: é›£æ˜“åº¦ï¼ˆeasy/medium/hardï¼‰
   {"â€»ä¼æ¥­æ¥ç¶šã®æŒ‡æ‘˜ã§ã¯ã€æä¾›ã•ã‚ŒãŸä¼æ¥­æƒ…å ±ã‚’å‚ç…§ã—ã€ã€ã€‡ã€‡äº‹æ¥­ã¸ã®è¨€åŠãŒãªã„ã€ã€â–³â–³ã¨ã„ã†ä¼æ¥­ç†å¿µã¨ã®æ¥ç‚¹ãŒä¸æ˜ç¢ºã€ãªã©ã€å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’ç¤ºã—ã¦ãã ã•ã„" if company_rag_available else ""}

3. rewrites: æ”¹å–„ä¾‹ï¼ˆ{rewrite_count}ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
   - ã‚¹ã‚¿ã‚¤ãƒ«ã€Œ{request.style}ã€ã«æ²¿ã£ã¦{rewrite_instruction}ãƒªãƒ©ã‚¤ãƒˆ
   - å…ƒã®æ–‡ç« ã®è‰¯ã„éƒ¨åˆ†ã¯æ´»ã‹ã—ã¤ã¤ã€å•é¡Œç‚¹ã‚’æ”¹å–„ã—ãŸæ–‡ç« 
   - å…ƒã®æ–‡ç« ã¨åŒç¨‹åº¦ã®é•·ã•ã§
   {"- ä¼æ¥­æƒ…å ±ã«åŸºã¥ã„ã¦ã€ä¼æ¥­ã®äº‹æ¥­å†…å®¹ã‚„ä¾¡å€¤è¦³ã¨çµã³ã¤ãè¡¨ç¾ã‚’è¿½åŠ " if company_rag_available else ""}
{section_feedback_instruction}

ã‚¹ã‚³ã‚¢ã¯å³ã—ã‚ã«ä»˜ã‘ã¦ãã ã•ã„ï¼ˆå¹³å‡3ç‚¹ç¨‹åº¦ï¼‰ã€‚
æ”¹å–„æ¡ˆã¯å…·ä½“çš„ã§ã€ã™ãã«å®Ÿè·µã§ãã‚‹ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšæœ‰åŠ¹ãªJSONã§å›ç­”ï¼‰:
{{
  "scores": {{"logic": 3, "specificity": 3, "passion": 3, "readability": 3{', "company_connection": 3' if company_rag_available else ''}}},
  "top3": [
    {{"category": "...", "issue": "...", "suggestion": "...", "difficulty": "easy"}}
  ],
  "rewrites": ["ãƒªãƒ©ã‚¤ãƒˆ1", "ãƒªãƒ©ã‚¤ãƒˆ2", ...],
  "section_feedbacks": [{{"section_title": "...", "feedback": "...", "rewrite": "..."}}]
}}"""

    # Inject gakuchika context if available
    gakuchika_context_section = ""
    if request.gakuchika_context:
        gakuchika_context_section = f"""

**ã‚¬ã‚¯ãƒã‚«æ·±æ˜ã‚Šæƒ…å ±:**
ä»¥ä¸‹ã¯ã‚¬ã‚¯ãƒã‚«ï¼ˆå­¦ç”Ÿæ™‚ä»£ã«åŠ›ã‚’å…¥ã‚ŒãŸã“ã¨ï¼‰ã®æ·±æ˜ã‚Šã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã§ã™ã€‚
ESã®æ·»å‰Šã«ãŠã„ã¦ã€ã“ã‚Œã‚‰ã®çµŒé¨“ã‚„å¼·ã¿ãŒæ´»ã‹ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åæ˜ ã—ã¦ãã ã•ã„ã€‚

{request.gakuchika_context}
"""

    # Build user message with company context if available
    user_message = f"ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ï¼š\n\n{request.content}"
    if company_context:
        user_message = f"""ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚

**ä¼æ¥­æƒ…å ±ï¼ˆRAGã‹ã‚‰å–å¾—ï¼‰:**
ä»¥ä¸‹ã¯ä¼æ¥­ã®æ¡ç”¨ãƒšãƒ¼ã‚¸ã€IRæƒ…å ±ã€äº‹æ¥­ç´¹ä»‹ã‹ã‚‰æŠ½å‡ºã—ãŸæƒ…å ±ã§ã™ã€‚ESã®ã€Œä¼æ¥­æ¥ç¶šã€è©•ä¾¡ã«ãŠã„ã¦ã€ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’å‚ç…§ã—ã¦å…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

{company_context}
{gakuchika_context_section}
**ESå†…å®¹:**
{request.content}

**è©•ä¾¡ã®ãƒã‚¤ãƒ³ãƒˆ:**
- ä¼æ¥­æƒ…å ±ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹äº‹æ¥­å†…å®¹ã€ä¾¡å€¤è¦³ã€æ±‚ã‚ã‚‹äººæåƒã¨ESã®å†…å®¹ãŒçµã³ã¤ã„ã¦ã„ã‚‹ã‹
- ä¼æ¥­ã®å…·ä½“çš„ãªå–ã‚Šçµ„ã¿ã‚„ç‰¹å¾´ã«è¨€åŠã—ã¦ã„ã‚‹ã‹
- å¿—æœ›å‹•æ©ŸãŒä¼æ¥­ã®å®Ÿæ…‹ã«å³ã—ã¦ã„ã‚‹ã‹"""
    else:
        # No company context, but may have gakuchika context
        if gakuchika_context_section:
            user_message = f"""ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚
{gakuchika_context_section}
**ESå†…å®¹:**
{request.content}"""

    include_section_feedbacks = bool(
        request.is_paid and (request.section_data or request.sections)
    )

    # feature="es_review" â†’ automatically selects Claude Sonnet
    llm_result = await call_llm_with_error(
        system_prompt=system_prompt,
        user_message=user_message,
        max_tokens=3000,
        temperature=0.3,
        feature="es_review",
        response_format="json_schema",
        json_schema=build_es_review_schema(
            require_company_connection=company_rag_available,
            include_template_review=False,
            include_section_feedbacks=include_section_feedbacks,
        ),
        use_responses_api=True,
        retry_on_parse=True,
        parse_retry_instructions="å¿…ãšæœ‰åŠ¹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯ç¦æ­¢ã§ã™ã€‚",
        disable_fallback=True,
    )

    if not llm_result.success:
        # Return detailed error to client
        error = llm_result.error
        error_detail = {
            "error": error.message if error else "AIå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
            "error_type": error.error_type if error else "unknown",
            "provider": error.provider if error else "unknown",
            "detail": error.detail if error else "",
        }
        raise HTTPException(status_code=503, detail=error_detail)

    data = llm_result.data
    if data is None:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AIã‹ã‚‰ã®å¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "error_type": "parse",
                "provider": "unknown",
                "detail": "Empty response from LLM",
            },
        )

    try:
        # Validate and construct response
        scores_data = data.get("scores", {})
        scores = Score(
            logic=max(1, min(5, scores_data.get("logic", 3))),
            specificity=max(1, min(5, scores_data.get("specificity", 3))),
            passion=max(1, min(5, scores_data.get("passion", 3))),
            company_connection=(
                max(1, min(5, scores_data.get("company_connection", 3)))
                if company_rag_available
                else None
            ),
            readability=max(1, min(5, scores_data.get("readability", 3))),
        )

        top3_data = data.get("top3", [])
        top3 = _parse_issues(top3_data, 3)

        # Ensure we have 3 issues
        while len(top3) < 3:
            top3.append(
                Issue(
                    category="ãã®ä»–",
                    issue="è¿½åŠ ã®æ”¹å–„ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    suggestion="å…¨ä½“çš„ãªè¦‹ç›´ã—ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„",
                    difficulty="medium",
                )
            )

        # Get rewrites (handle both array and single string)
        rewrites_data = data.get("rewrites", [])
        if isinstance(rewrites_data, str):
            rewrites_data = [rewrites_data]
        rewrites = rewrites_data[:rewrite_count] if rewrites_data else [request.content]

        # Get section feedbacks (paid only)
        # With character limit validation for rewrites
        section_feedbacks = None
        if request.is_paid and (request.section_data or request.sections):
            sf_data = data.get("section_feedbacks", [])
            if sf_data:
                # Build a lookup for section char limits
                section_char_limits: dict[str, Optional[int]] = {}
                if request.section_data:
                    for sd in request.section_data:
                        section_char_limits[sd.title] = sd.char_limit

                section_feedbacks = []
                for item in sf_data:
                    section_title = item.get("section_title", "")
                    raw_rewrite = item.get("rewrite")

                    # Find char limit for this section and validate rewrite
                    char_limit = section_char_limits.get(section_title)
                    validated_rewrite = validate_and_repair_section_rewrite(
                        raw_rewrite, char_limit
                    )

                    section_feedbacks.append(
                        SectionFeedback(
                            section_title=section_title,
                            feedback=item.get("feedback", "")[:150],
                            rewrite=validated_rewrite,
                        )
                    )

        result = ReviewResponse(
            scores=scores,
            top3=top3,
            rewrites=rewrites,
            section_feedbacks=section_feedbacks,
        )
        record_es_scores(result.scores.model_dump())
        if cache:
            await cache.set_review(cache_key, result.model_dump())
        return result

    except Exception as e:
        print(f"[ESæ·»å‰Š] âŒ LLMå¿œç­”è§£æå¤±æ•—: {e}")
        record_parse_failure("es_review_full", str(e))
        raise HTTPException(
            status_code=503,
            detail={
                "error": "AIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "error_type": "parse",
                "provider": "unknown",
                "detail": str(e),
            },
        )


# ============================================================================
# SSE Streaming Endpoint for Real-time Progress
# ============================================================================

# Progress step definitions for SSE events
PROGRESS_STEPS = [
    {
        "id": "validation",
        "label": "å…¥åŠ›ã‚’æ¤œè¨¼ä¸­...",
        "subLabel": "å†…å®¹ã®ç¢ºèª",
    },
    {
        "id": "rag_fetch",
        "label": "ä¼æ¥­æƒ…å ±ã‚’å–å¾—ä¸­...",
        "subLabel": "RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢",
    },
    {
        "id": "llm_review",
        "label": "AIãŒæ·»å‰Šä¸­...",
        "subLabel": "ã‚¹ã‚³ã‚¢ã¨æ”¹å–„ç‚¹ã‚’åˆ†æ",
    },
    {
        "id": "rewrite",
        "label": "ãƒªãƒ©ã‚¤ãƒˆã‚’ç”Ÿæˆä¸­...",
        "subLabel": "è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆ",
    },
    {
        "id": "retry",
        "label": "æ–‡å­—æ•°ã‚’èª¿æ•´ä¸­...",
        "subLabel": "ãƒªãƒˆãƒ©ã‚¤å‡¦ç†",
    },
]


def _sse_event(event_type: str, data: dict) -> str:
    """Format SSE event data."""
    payload = {"type": event_type, **data}
    return f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"


async def _generate_review_progress(
    request: ReviewRequest,
) -> AsyncGenerator[str, None]:
    """
    Generate SSE events for ES review progress.
    Yields progress updates as the review is processed.
    """
    try:
        # Step 1: Validation
        yield _sse_event(
            "progress",
            {"step": "validation", "progress": 5, "label": "å…¥åŠ›ã‚’æ¤œè¨¼ä¸­..."},
        )
        await asyncio.sleep(0.1)  # Small delay to ensure event is sent

        if not request.content or len(request.content.strip()) < 10:
            yield _sse_event(
                "error",
                {
                    "message": "ESã®å†…å®¹ãŒçŸ­ã™ãã¾ã™ã€‚ã‚‚ã†å°‘ã—è©³ã—ãæ›¸ã„ã¦ã‹ã‚‰æ·»å‰Šã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚"
                },
            )
            return

        # Validate review_mode
        if request.review_mode not in ("full", "section"):
            yield _sse_event(
                "error",
                {"message": "review_modeã¯ 'full' ã¾ãŸã¯ 'section' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"},
            )
            return

        # Validate style
        available_styles = PAID_STYLES if request.is_paid else FREE_STYLES
        if request.style not in available_styles:
            yield _sse_event(
                "error",
                {"message": f"åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚¿ã‚¤ãƒ«: {', '.join(available_styles)}"},
            )
            return

        yield _sse_event(
            "progress",
            {"step": "validation", "progress": 10, "label": "æ¤œè¨¼å®Œäº†"},
        )

        # Step 2: RAG fetch (if company_id)
        rewrite_count = min(request.rewrite_count, settings.es_rewrite_count if request.is_paid else 1)
        company_context = ""
        rag_context = ""
        rag_sources: list[dict] = []
        company_rag_available = request.has_company_rag
        rag_status = None
        context_length = get_dynamic_context_length(request.content)

        if request.company_id:
            yield _sse_event(
                "progress",
                {
                    "step": "rag_fetch",
                    "progress": 15,
                    "label": "ä¼æ¥­æƒ…å ±ã‚’å–å¾—ä¸­...",
                },
            )

            if not company_rag_available:
                company_rag_available = has_company_rag(request.company_id)

            if company_rag_available:
                rag_status = get_company_rag_status(request.company_id)
                min_context_length = max(0, settings.rag_min_context_chars)

                if request.review_mode == "section":
                    rag_context, rag_sources = (
                        await get_enhanced_context_for_review_with_sources(
                            company_id=request.company_id,
                            es_content=request.content,
                            max_context_length=context_length,
                        )
                    )
                    if len(rag_context) < min_context_length or not rag_sources:
                        rag_context = ""
                        rag_sources = []
                        company_rag_available = False
                else:
                    company_context = await get_enhanced_context_for_review(
                        company_id=request.company_id,
                        es_content=request.content,
                        max_context_length=context_length,
                    )
                    if (
                        not company_context
                        or len(company_context) < min_context_length
                    ):
                        company_context = ""
                        company_rag_available = False

                record_rag_context(
                    company_id=request.company_id,
                    context_length=len(rag_context or company_context),
                    source_count=(
                        len(rag_sources)
                        if rag_sources
                        else (rag_status.get("total_chunks", 0) if rag_status else 0)
                    ),
                )

            yield _sse_event(
                "progress",
                {
                    "step": "rag_fetch",
                    "progress": 30,
                    "label": "ä¼æ¥­æƒ…å ±å–å¾—å®Œäº†"
                    if company_rag_available
                    else "ä¼æ¥­æƒ…å ±ãªã—",
                },
            )
        else:
            yield _sse_event(
                "progress",
                {"step": "rag_fetch", "progress": 30, "label": "ã‚¹ã‚­ãƒƒãƒ—"},
            )

        # Step 3: LLM Review
        yield _sse_event(
            "progress",
            {"step": "llm_review", "progress": 35, "label": "AIãŒæ·»å‰Šä¸­..."},
        )

        # Section mode (always template-based) handled here for SSE
        if request.review_mode == "section":
            try:
                template_request = request.template_request
                if not template_request:
                    char_max = request.section_char_limit
                    char_min = (
                        char_max - max(20, math.floor(char_max * 0.10))
                        if char_max
                        else None
                    )
                    template_request = TemplateRequest(
                        template_type="basic",
                        company_name=None,
                        industry=None,
                        question=request.section_title or "",
                        answer=request.content,
                        char_min=char_min,
                        char_max=char_max,
                    )

                template_request_request = (
                    request
                    if request.template_request
                    else request.model_copy(
                        update={"template_request": template_request}
                    )
                )

                # Use asyncio.Queue to stream progress during LLM call
                progress_queue: asyncio.Queue = asyncio.Queue(maxsize=100)

                async def _run_template_review():
                    return await review_section_with_template(
                        request=template_request_request,
                        rag_context=rag_context,
                        rag_sources=rag_sources,
                        company_rag_available=company_rag_available,
                        progress_queue=progress_queue,
                    )

                # Launch review as a task so we can yield progress events concurrently
                review_task = asyncio.create_task(_run_template_review())

                # Consume progress events from queue while task runs
                while not review_task.done():
                    try:
                        event_type, event_data = await asyncio.wait_for(
                            progress_queue.get(), timeout=0.5
                        )
                        if event_type == "progress":
                            yield _sse_event("progress", event_data)
                    except asyncio.TimeoutError:
                        # No event in queue, check if task is done
                        continue

                # Drain remaining events from queue
                while not progress_queue.empty():
                    try:
                        event_type, event_data = progress_queue.get_nowait()
                        if event_type == "progress":
                            yield _sse_event("progress", event_data)
                    except asyncio.QueueEmpty:
                        break

                # Get the result (may raise exception)
                result = await review_task

            except HTTPException as e:
                detail = e.detail
                if isinstance(detail, dict):
                    message = (
                        detail.get("error")
                        or detail.get("message")
                        or detail.get("detail")
                        or "AIå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
                    )
                else:
                    message = str(detail)
                yield _sse_event("error", {"message": message})
                return
            except Exception as e:
                yield _sse_event("error", {"message": str(e)})
                return

            yield _sse_event(
                "progress",
                {
                    "step": "rewrite",
                    "progress": 90,
                    "label": "ãƒªãƒ©ã‚¤ãƒˆã‚’ç”Ÿæˆä¸­...",
                },
            )
            yield _sse_event(
                "progress",
                {"step": "rewrite", "progress": 100, "label": "å®Œäº†"},
            )
            yield _sse_event("complete", {"result": result.model_dump()})
            return

        # Build scoring criteria
        score_criteria = """1. scores (å„1-5ç‚¹):
   - logic: è«–ç†ã®ä¸€è²«æ€§ï¼ˆä¸»å¼µã¨æ ¹æ‹ ã®æ•´åˆæ€§ã€å› æœé–¢ä¿‚ã®æ˜ç¢ºã•ï¼‰
   - specificity: å…·ä½“æ€§ï¼ˆæ•°å­—ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã€å›ºæœ‰åè©ã®ä½¿ç”¨ï¼‰
   - passion: ç†±æ„ãƒ»æ„æ¬²ã®ä¼ã‚ã‚Šåº¦ï¼ˆãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®èª¬å¾—åŠ›ï¼‰"""

        if company_rag_available:
            score_criteria += """
   - company_connection: ä¼æ¥­æ¥ç¶šï¼ˆä¼æ¥­æƒ…å ±ã«åŸºã¥ã„ã¦è©•ä¾¡ï¼‰"""

        score_criteria += """
   - readability: èª­ã¿ã‚„ã™ã•ï¼ˆæ–‡ç« ã®æ˜ç­ã•ã€æ§‹æˆã®åˆ†ã‹ã‚Šã‚„ã™ã•ï¼‰"""

        # Build style instructions
        style_instructions = {
            "ãƒãƒ©ãƒ³ã‚¹": "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã€èª­ã¿ã‚„ã™ã„æ–‡ç« ã«",
            "å …ã‚": "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§å …å®Ÿãªå°è±¡ã®æ–‡ç« ã«",
            "å€‹æ€§å¼·ã‚": "å€‹æ€§ã¨ç‹¬è‡ªæ€§ãŒéš›ç«‹ã¤æ–‡ç« ã«",
            "çŸ­ã": "ç°¡æ½”ã§ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªæ–‡ç« ã«",
            "ç†±æ„å¼·ã‚": "ç†±æ„ã¨æ„æ¬²ãŒå¼·ãä¼ã‚ã‚‹æ–‡ç« ã«",
            "çµè«–å…ˆå‡ºã—": "çµè«–ã‚’å…ˆã«è¿°ã¹ã€æ ¹æ‹ ã‚’å¾Œã‹ã‚‰ç¤ºã™æ§‹æˆã«",
            "å…·ä½“ä¾‹å¼·ã‚": "å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„æ•°å€¤ã‚’å¢—ã‚„ã—ãŸæ–‡ç« ã«",
            "ç«¯çš„": "ç«¯çš„ã§è¦ç‚¹ã‚’æŠ¼ã•ãˆãŸæ–‡ç« ã«",
        }
        rewrite_instruction = style_instructions.get(
            request.style, "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ–‡ç« ã«"
        )

        # Section feedback instruction (paid only)
        section_feedback_instruction = ""
        if request.is_paid and request.section_data:
            section_items = []
            for s in request.section_data:
                limit_note = (
                    f"ï¼ˆæ–‡å­—æ•°åˆ¶é™: {s.char_limit}æ–‡å­—ï¼‰" if s.char_limit else ""
                )
                section_items.append(f"   - {s.title}{limit_note}")
            section_list = "\n".join(section_items)
            section_feedback_instruction = f"""
4. section_feedbacks: è¨­å•åˆ¥ã®æŒ‡æ‘˜ã¨æ”¹å–„ä¾‹
   ä»¥ä¸‹ã®å„è¨­å•ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ”¹å–„ç‚¹ã¨æ”¹å–„ä¾‹ã‚’æä¾›ã—ã¦ãã ã•ã„:
{section_list}
   - section_title: è¨­å•ã‚¿ã‚¤ãƒˆãƒ«
   - feedback: ãã®è¨­å•ã«ç‰¹åŒ–ã—ãŸæ”¹å–„ç‚¹ï¼ˆ100-150å­—ï¼‰
   - rewrite: æ”¹å–„ä¾‹ï¼ˆæ–‡å­—æ•°åˆ¶é™ãŒã‚ã‚‹å ´åˆã¯ãã®æ–‡å­—æ•°ä»¥å†…ã§ï¼‰"""
        elif request.is_paid and request.sections:
            section_list = "\n".join([f"   - {s}" for s in request.sections])
            section_feedback_instruction = f"""
4. section_feedbacks: è¨­å•åˆ¥ã®æŒ‡æ‘˜ï¼ˆ100-150å­—/è¨­å•ï¼‰
   ä»¥ä¸‹ã®å„è¨­å•ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„:
{section_list}
   - section_title: è¨­å•ã‚¿ã‚¤ãƒˆãƒ«
   - feedback: ãã®è¨­å•ã«ç‰¹åŒ–ã—ãŸæ”¹å–„ç‚¹ï¼ˆ100-150å­—ï¼‰"""

        system_prompt = f"""ã‚ãªãŸã¯ESï¼ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ãƒ¼ãƒˆï¼‰æ·»å‰Šã®å°‚é–€å®¶ã§ã™ã€‚
å°±æ´»ç”Ÿã®ESã‚’æ·»å‰Šã—ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®è¦³ç‚¹ã§è©•ä¾¡ã—ã€å¿…ãšJSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{score_criteria}

2. top3: æ”¹å–„ã™ã¹ãä¸Šä½3ç‚¹
   - category: è©•ä¾¡è»¸ã®åå‰
   - issue: å…·ä½“çš„ãªå•é¡Œç‚¹
   - suggestion: å®Ÿè·µçš„ãªæ”¹å–„æ¡ˆ
   - difficulty: é›£æ˜“åº¦ï¼ˆeasy/medium/hardï¼‰

3. rewrites: æ”¹å–„ä¾‹ï¼ˆ{rewrite_count}ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
   - ã‚¹ã‚¿ã‚¤ãƒ«ã€Œ{request.style}ã€ã«æ²¿ã£ã¦{rewrite_instruction}ãƒªãƒ©ã‚¤ãƒˆ
{section_feedback_instruction}

ã‚¹ã‚³ã‚¢ã¯å³ã—ã‚ã«ä»˜ã‘ã¦ãã ã•ã„ã€‚
å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšæœ‰åŠ¹ãªJSONã§å›ç­”ï¼‰:
{{
  "scores": {{"logic": 3, "specificity": 3, "passion": 3, "readability": 3{', "company_connection": 3' if company_rag_available else ''}}},
  "top3": [{{"category": "...", "issue": "...", "suggestion": "...", "difficulty": "easy"}}],
  "rewrites": ["ãƒªãƒ©ã‚¤ãƒˆ1"],
  "section_feedbacks": [{{"section_title": "...", "feedback": "..."}}]
}}"""

        # Inject gakuchika context if available
        gakuchika_context_section = ""
        if request.gakuchika_context:
            gakuchika_context_section = f"""

**ã‚¬ã‚¯ãƒã‚«æ·±æ˜ã‚Šæƒ…å ±:**
ä»¥ä¸‹ã¯ã‚¬ã‚¯ãƒã‚«ï¼ˆå­¦ç”Ÿæ™‚ä»£ã«åŠ›ã‚’å…¥ã‚ŒãŸã“ã¨ï¼‰ã®æ·±æ˜ã‚Šã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã§ã™ã€‚
ESã®æ·»å‰Šã«ãŠã„ã¦ã€ã“ã‚Œã‚‰ã®çµŒé¨“ã‚„å¼·ã¿ãŒæ´»ã‹ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åæ˜ ã—ã¦ãã ã•ã„ã€‚

{request.gakuchika_context}
"""

        user_message = f"ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ï¼š\n\n{request.content}"
        if company_context:
            user_message = f"""ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚

**ä¼æ¥­æƒ…å ±ï¼ˆRAGã‹ã‚‰å–å¾—ï¼‰:**
{company_context}
{gakuchika_context_section}
**ESå†…å®¹:**
{request.content}"""
        else:
            # No company context, but may have gakuchika context
            if gakuchika_context_section:
                user_message = f"""ä»¥ä¸‹ã®ESã‚’æ·»å‰Šã—ã¦ãã ã•ã„ã€‚
{gakuchika_context_section}
**ESå†…å®¹:**
{request.content}"""

        yield _sse_event(
            "progress",
            {"step": "llm_review", "progress": 50, "label": "AIãŒåˆ†æä¸­..."},
        )

        include_section_feedbacks = bool(
            request.is_paid and (request.section_data or request.sections)
        )

        llm_result = await call_llm_with_error(
            system_prompt=system_prompt,
            user_message=user_message,
            max_tokens=3000,
            temperature=0.3,
            feature="es_review",
            response_format="json_schema",
            json_schema=build_es_review_schema(
                require_company_connection=company_rag_available,
                include_template_review=False,
                include_section_feedbacks=include_section_feedbacks,
            ),
            use_responses_api=True,
            retry_on_parse=True,
            parse_retry_instructions="å¿…ãšæœ‰åŠ¹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
            disable_fallback=True,
        )

        yield _sse_event(
            "progress",
            {"step": "llm_review", "progress": 80, "label": "æ·»å‰Šå®Œäº†"},
        )

        if not llm_result.success:
            error = llm_result.error
            yield _sse_event(
                "error",
                {
                    "message": error.message
                    if error
                    else "AIå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
                },
            )
            return

        data = llm_result.data
        if data is None:
            yield _sse_event(
                "error",
                {"message": "AIã‹ã‚‰ã®å¿œç­”ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"},
            )
            return

        # Step 4: Rewrite generation (parsing results)
        yield _sse_event(
            "progress",
            {
                "step": "rewrite",
                "progress": 90,
                "label": "ãƒªãƒ©ã‚¤ãƒˆã‚’ç”Ÿæˆä¸­...",
            },
        )

        # Parse and validate response
        scores_data = data.get("scores", {})
        scores = {
            "logic": max(1, min(5, scores_data.get("logic", 3))),
            "specificity": max(1, min(5, scores_data.get("specificity", 3))),
            "passion": max(1, min(5, scores_data.get("passion", 3))),
            "readability": max(1, min(5, scores_data.get("readability", 3))),
        }
        if company_rag_available:
            scores["company_connection"] = max(
                1, min(5, scores_data.get("company_connection", 3))
            )

        top3_data = data.get("top3", [])
        top3 = []
        for item in top3_data[:3]:
            top3.append(
                {
                    "category": item.get("category", "ãã®ä»–"),
                    "issue": item.get("issue", ""),
                    "suggestion": item.get("suggestion", ""),
                    "difficulty": item.get("difficulty", "medium"),
                }
            )

        while len(top3) < 3:
            top3.append(
                {
                    "category": "ãã®ä»–",
                    "issue": "è¿½åŠ ã®æ”¹å–„ç‚¹ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    "suggestion": "å…¨ä½“çš„ãªè¦‹ç›´ã—ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„",
                    "difficulty": "medium",
                }
            )

        rewrites_data = data.get("rewrites", [])
        if isinstance(rewrites_data, str):
            rewrites_data = [rewrites_data]
        rewrites = (
            rewrites_data[:rewrite_count] if rewrites_data else [request.content]
        )

        section_feedbacks = None
        if request.is_paid and (request.section_data or request.sections):
            sf_data = data.get("section_feedbacks", [])
            if sf_data:
                section_char_limits: dict[str, Optional[int]] = {}
                if request.section_data:
                    for sd in request.section_data:
                        section_char_limits[sd.title] = sd.char_limit

                section_feedbacks = []
                for item in sf_data:
                    section_title = item.get("section_title", "")
                    raw_rewrite = item.get("rewrite")
                    char_limit = section_char_limits.get(section_title)
                    validated_rewrite = validate_and_repair_section_rewrite(
                        raw_rewrite, char_limit
                    )
                    section_feedbacks.append(
                        {
                            "section_title": section_title,
                            "feedback": item.get("feedback", "")[:150],
                            "rewrite": validated_rewrite,
                        }
                    )

        yield _sse_event(
            "progress",
            {"step": "rewrite", "progress": 100, "label": "å®Œäº†"},
        )

        # Final complete event with result
        result = {
            "scores": scores,
            "top3": top3,
            "rewrites": rewrites,
            "section_feedbacks": section_feedbacks,
        }

        yield _sse_event("complete", {"result": result})

    except Exception as e:
        print(f"[ESæ·»å‰Š/SSE] âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        yield _sse_event("error", {"message": str(e)})


@router.post("/review/stream")
async def review_es_stream(request: ReviewRequest):
    """
    Stream ES review progress via Server-Sent Events (SSE).

    This endpoint provides real-time progress updates during ES review,
    allowing the frontend to show accurate progress to users.

    Events:
    - progress: {"type": "progress", "step": "...", "progress": 0-100, "label": "..."}
    - complete: {"type": "complete", "result": {...}}
    - error: {"type": "error", "message": "..."}
    """
    return StreamingResponse(
        _generate_review_progress(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx buffering
        },
    )
